{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0a63fe-5632-4301-a952-1c91b9ac964c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 选择镜像：unimol-qsar:v0.5, 机型选择GPU\n",
    "# 导入unimol\n",
    "from unimol import UniMolRepr\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecdae04-19d7-41a7-9f05-ca73908d1bec",
   "metadata": {},
   "source": [
    "### 多分子输入做大指纹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d70a93-e261-4015-b67d-103b7105b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = UniMolRepr(data_type='molecule', remove_hs=False)\n",
    "\n",
    "# Load dataset\n",
    "filename = 'truncated_MON.csv'\n",
    "df = pd.read_csv(filename)\n",
    "y = df['TARGET'].to_list()\n",
    "\n",
    "# SMILES column names\n",
    "smiles_fields = ['SMILES_1', 'SMILES_2', 'SMILES_3', 'SMILES_4']\n",
    "\n",
    "# Initialize a new dataframe\n",
    "big_fingerprint_df = pd.DataFrame()\n",
    "\n",
    "# Initialize DataFrame, filled with NaN\n",
    "# Assume that each SMILES generated representation has 512 dimensions\n",
    "num_repr_dimensions = 512\n",
    "big_fingerprint_df = pd.DataFrame(np.nan, index=np.arange(len(df)), columns=np.arange(len(smiles_fields) * num_repr_dimensions))\n",
    "\n",
    "# for each SMILES column\n",
    "for field_idx, field in enumerate(smiles_fields):\n",
    "    smiles_list = df[field].to_list()\n",
    "    \n",
    "    # if SMILES col is not empty\n",
    "    non_empty_smiles = [smiles for smiles in smiles_list if pd.notna(smiles) and smiles != '']\n",
    "    if non_empty_smiles:\n",
    "        repr_dict = clf.get_repr(non_empty_smiles)\n",
    "        unimol_repr_list = np.array(repr_dict['cls_repr'])\n",
    "        \n",
    "        # columns range which should be processed\n",
    "        col_start = field_idx * num_repr_dimensions\n",
    "        col_end = (field_idx + 1) * num_repr_dimensions\n",
    "        \n",
    "        # Only update rows corresponding to non-empty SMILES\n",
    "        for i, smiles in enumerate(smiles_list):\n",
    "            if smiles in non_empty_smiles:\n",
    "                big_fingerprint_df.iloc[i, col_start:col_end] = unimol_repr_list[non_empty_smiles.index(smiles)]\n",
    "\n",
    "\n",
    "# Append到大指纹DataFrame\n",
    "big_fingerprint_df['TARGET'] = y\n",
    "big_fingerprint_df.to_csv('Uni-fingerprint_'+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf2e48a-b8cc-4708-b4b8-fac67b03da2f",
   "metadata": {},
   "source": [
    "### 多分子带权指纹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9865164-df6d-40bb-84a4-edd631c73f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 22:48:14 | unimol/models/unimol.py | 116 | INFO | Uni-Mol(QSAR) | Loading pretrained weights from /opt/conda/lib/python3.8/site-packages/unimol-0.0.2-py3.8.egg/unimol/weights/mol_pre_all_h_220816.pt\n",
      "2024-02-29 22:48:17 | unimol/data/conformer.py | 62 | INFO | Uni-Mol(QSAR) | Start generating conformers...\n",
      "33it [00:00, 137.63it/s]\n",
      "2024-02-29 22:48:17 | unimol/data/conformer.py | 66 | INFO | Uni-Mol(QSAR) | Failed to generate conformers for 0.00% of molecules.\n",
      "2024-02-29 22:48:17 | unimol/data/conformer.py | 68 | INFO | Uni-Mol(QSAR) | Failed to generate 3d conformers for 0.00% of molecules.\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.17it/s]\n",
      "2024-02-29 22:48:18 | unimol/data/conformer.py | 62 | INFO | Uni-Mol(QSAR) | Start generating conformers...\n",
      "33it [00:00, 142.55it/s]\n",
      "2024-02-29 22:48:18 | unimol/data/conformer.py | 66 | INFO | Uni-Mol(QSAR) | Failed to generate conformers for 0.00% of molecules.\n",
      "2024-02-29 22:48:18 | unimol/data/conformer.py | 68 | INFO | Uni-Mol(QSAR) | Failed to generate 3d conformers for 0.00% of molecules.\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.32it/s]\n",
      "2024-02-29 22:48:19 | unimol/data/conformer.py | 62 | INFO | Uni-Mol(QSAR) | Start generating conformers...\n",
      "22it [00:00, 217.98it/s]\n",
      "2024-02-29 22:48:19 | unimol/data/conformer.py | 66 | INFO | Uni-Mol(QSAR) | Failed to generate conformers for 0.00% of molecules.\n",
      "2024-02-29 22:48:19 | unimol/data/conformer.py | 68 | INFO | Uni-Mol(QSAR) | Failed to generate 3d conformers for 0.00% of molecules.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "2024-02-29 22:48:20 | unimol/data/conformer.py | 62 | INFO | Uni-Mol(QSAR) | Start generating conformers...\n",
      "3it [00:00, 39.13it/s]\n",
      "2024-02-29 22:48:20 | unimol/data/conformer.py | 66 | INFO | Uni-Mol(QSAR) | Failed to generate conformers for 0.00% of molecules.\n",
      "2024-02-29 22:48:20 | unimol/data/conformer.py | 68 | INFO | Uni-Mol(QSAR) | Failed to generate 3d conformers for 0.00% of molecules.\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = UniMolRepr(data_type='molecule', remove_hs=False)\n",
    "\n",
    "# Load dataset\n",
    "filename = 'truncated_MON.csv'\n",
    "df = pd.read_csv(filename)\n",
    "y = df['TARGET'].to_list()\n",
    "\n",
    "# SMILES and Ratio column names\n",
    "smiles_fields = ['SMILES_1', 'SMILES_2', 'SMILES_3', 'SMILES_4']\n",
    "ratio_fields = ['Ratio_0', 'Ratio_1', 'Ratio_2', 'Ratio_3']  # Corresponding ratio fields\n",
    "\n",
    "# Initialize DataFrame, filled with NaN\n",
    "# Assume that each SMILES generated representation has 512 dimensions\n",
    "num_repr_dimensions = 512\n",
    "big_fingerprint_df = pd.DataFrame(np.nan, index=np.arange(len(df)), columns=np.arange(len(smiles_fields) * num_repr_dimensions))\n",
    "\n",
    "# for each (SMILES column and its Ratio) column (pair)s\n",
    "for field_idx, (smiles_field, ratio_field) in enumerate(zip(smiles_fields, ratio_fields)):\n",
    "    smiles_list = df[smiles_field].to_list()\n",
    "    ratio_list = df[ratio_field].to_list()  # 获取对应的加权比例列表\n",
    "    \n",
    "    # if SMILES col is not empty\n",
    "    non_empty_smiles = [(smiles, ratio) for smiles, ratio in zip(smiles_list, ratio_list) if pd.notna(smiles) and smiles != '']\n",
    "    if non_empty_smiles:\n",
    "        # Separate the SMILES and its ratio\n",
    "        valid_smiles, valid_ratios = zip(*non_empty_smiles)\n",
    "        repr_dict = clf.get_repr(list(valid_smiles))\n",
    "        unimol_repr_list = np.array(repr_dict['cls_repr'])\n",
    "        \n",
    "        # columns range which should be processed\n",
    "        col_start = field_idx * num_repr_dimensions\n",
    "        col_end = (field_idx + 1) * num_repr_dimensions\n",
    "        \n",
    "        # Update non-empty SMILES and apply weighted ratios\n",
    "        for i, (smiles, ratio) in enumerate(zip(smiles_list, ratio_list)):\n",
    "            if smiles in valid_smiles:\n",
    "                weighted_repr = unimol_repr_list[valid_smiles.index(smiles)] * ratio  # 应用加权\n",
    "                big_fingerprint_df.iloc[i, col_start:col_end] = weighted_repr\n",
    "\n",
    "# Append到大指纹DataFrame\n",
    "big_fingerprint_df /= 100.0\n",
    "big_fingerprint_df['TARGET'] = y\n",
    "big_fingerprint_df.to_csv('Uni-fingerprint_'+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf982f54",
   "metadata": {},
   "source": [
    "## XGBoost给出预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97319bda-25a0-4d0b-a4bf-cab69db0bb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available.\n",
      "RMSE: 2.433807\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "\n",
    "# 分割数据为特征集(X)和目标变量(y)\n",
    "big_fingerprint_df = pd.read_csv('Uni-fingerprint_truncated_MON.csv')\n",
    "X = big_fingerprint_df.drop(['TARGET'], axis=1)\n",
    "y = big_fingerprint_df['TARGET']\n",
    "\n",
    "# 分割数据为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 初始化XGBoost回归模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device} is available.')\n",
    "xg_reg = xgb.XGBRegressor(\n",
    "    n_estimators = 400, objective ='reg:squarederror', colsample_bytree = 0.3, \n",
    "    learning_rate = 0.03, max_depth = 5, alpha = 10,\n",
    "    tree_method='gpu_hist' if device.type == 'cuda' else 'auto'\n",
    "    )\n",
    "\n",
    "# 训练模型\n",
    "xg_reg.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = xg_reg.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "# 使用整个数据集进行预测\n",
    "y_pred_full = xg_reg.predict(X)\n",
    "df['pred_y'] = y_pred_full\n",
    "df.to_csv('XGB_truncated_MON.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8befd5be-95ac-48bd-99b2-2d7430b19ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.5633347033037381\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 读取数据集\n",
    "data = pd.read_csv('XGB_test_MON.csv')  # 请将'your_dataset.csv'替换为你的数据集文件路径\n",
    "\n",
    "# 提取QSPR_pred列和TARGET列\n",
    "QSPR_pred = data['QSPR_pred']\n",
    "TARGET = data['TARGET']\n",
    "\n",
    "# 计算均方根误差（RMSE）\n",
    "rmse = np.sqrt(((QSPR_pred - TARGET) ** 2).mean())\n",
    "\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
